#!/usr/bin/python

import sys
import argparse
import theano
import theano.tensor as T
import numpy as np
import yaml

from cgml.io import DataReader
from cgml.argparse_actions import giveArgs
from cgml.computational_graph import ComputationalGraph

# Print outputs here
outStream = sys.stdout

# Print info here
infStream = sys.stderr

# Parsing the arguments
args = giveArgs(log = infStream)

# Open a log if needed
#log = ( open(args.log,'w') if args.log else None )

if args.load:

    infStream.write('\nLoading model from file: ' + args.load + '\n')

    model = ComputationalGraph.loadFromFile(args.load)

elif args.cg:

    # Create the model
    model = ComputationalGraph(schema = yaml.load(open(args.cg,'r')),
                               log   = infStream,
                               supCostWeight = args.supCostWeight,
                               unsupCostWeight = args.unsupCostWeight,
                               seed = args.seed)

if args.recompileOnLoad:
    model.compile(log = infStream)

#if model.type not in ['autoencoder']:
infStream.write(str(model.predict.maker.fgraph.toposort())+'\n')

# Check if GPU is being used or not
if np.any([isinstance(x.op, T.Elemwise) for x in model.predict.maker.fgraph.toposort()]):
    print 'No GPU found -- using CPU instead'
else:
    print 'Found GPU -- using that whenever possible'


# Write description of the model to infStream
infStream.write('\n' + str(model) + '\n')

if args.validData:

    infStream.write("Caching validation data for monitoring\n")

    x_valid,y_valid = DataReader(args.validData,
                                 targetType = model.targetType).cache()

infStream.write('\n')

if args.trainData:

    infStream.write("Starting to read input data for training\n")

    # Data reader for training
    drTrain = DataReader(args.trainData,
                         batchSize = args.deviceBatchSize,
                         targetType = model.targetType)
    

    nBatches = 0

    n = 0
    nTh = 100

    isSupCost = model.schema.get("supervised-cost")
    isUnSupCost = model.schema.get("unsupervised-cost")
    isHybridCost = isSupCost and isUnSupCost

    currMeanCost = 0.0
        
    for x_train,y_train in drTrain:
            
        model.setTrainDataOnDevice(x_train,y_train)
        
        for i in xrange(args.nPasses*args.deviceBatchSize/args.miniBatchSize):

            r = np.random.randint(args.deviceBatchSize-args.miniBatchSize)
            
            nBatches += 1
            n += 1 
            
            if isHybridCost:
                currMeanCost += model.hybrid_update(r,args.miniBatchSize) / n
            
            elif isSupCost:
                currMeanCost += model.supervised_update(r,args.miniBatchSize) / n
            elif isUnSupCost:
                currMeanCost += model.unsupervised_update(r,args.miniBatchSize) / n
                
            if n % nTh == 0:
                infStream.write('Batch ' + str(nBatches) + 
                                ', avg. train cost ' + str(currMeanCost))

                if args.validData:
                    if isHybridCost:
                        validSupCost = model.supervised_cost(x_valid,y_valid)
                        validUnsupCost = model.unsupervised_cost(x_valid)
                        validHybCost = model.hybrid_cost(x_valid,y_valid)
                        yhat = model.predict(x_valid)
                        pMisClass = np.mean(yhat != y_valid)
                        infStream.write(', valid.sup.cost ' + str(validSupCost) +
                                        ', valid.unsup.cost ' + str(validUnsupCost) + 
                                        ', valid.hyb.cost ' + str(validHybCost) + 
                                        ', classification error ' + str(100*pMisClass) + "%")
                        
                    elif isSupCost:
                        validCost = model.supervised_cost(x_valid,y_valid)
                        yhat = model.predict(x_valid)
                        pMisClass = np.mean(yhat != y_valid)
                        infStream.write(', validation cost ' + str(validCost) + 
                                        ', classification error ' + str(100*pMisClass) + "%")
                    elif isUnSupCost:
                        validCost = model.unsupervised_cost(x_valid)
                        infStream.write(', validation cost ' + str(validCost))
                    

                infStream.write('\n')

                n = 0

                currMeanCost = 0.0

                if args.verbose:
                    model.summarizeParams()


infStream.write('\n')

if args.save:
    
    infStream.write('Saving model to file: ' + args.save + '\n')

    model.saveToFile(args.save)

def strVec(vec):
    if type(vec) in [np.int64,int,np.float64,float]:
        return str(vec)
    return ' '.join(map(str,vec))

def strMat(mat):
    return '\n'.join(strVec(map(strVec,row)) for row in mat)
    
if args.testData:

    infStream.write("Starting to read data for prediction\n")
    
    # Data reader for prediction
    drTest  = DataReader(args.testData,
                         batchSize = 1,
                         targetType = model.targetType)
    
    # Start prediction
    for x_test,y_test in drTest:

        if model.type in ['classifier','regressor']:
            
            outStream.write( strMat(zip([y_test],model.predict(x_test))) + '\n' )
            
        elif model.type == 'autoencoder':
            
            outStream.write( strMat(zip([y_test],model.encode(x_test))) + '\n' )

        elif model.type == 'supervised-autoencoder':

            outStream.write( strMat(zip([y_test],
                                        model.predict(x_test),
                                        model.encode(x_test),
                                        model.decode(x_test))) + '\n' )









#!/usr/bin/python

import sys
import argparse
import theano.tensor as T
import numpy as np
import cPickle
import yaml

from cgml.io import DataReader
from cgml.argparse_actions import giveArgs
from cgml.computational_graph import ComputationalGraph

# Print outputs here
outStream = sys.stdout

# Print info here
infStream = sys.stderr

# Parsing the arguments
args = giveArgs(log = infStream)

# Open a log if needed
log = ( open(args.log,'w') if args.log else None )

if args.load:

    infStream.write('\nLoading model from file: ' + args.load + '\n')

    # Load the model
    f = open(args.load,'rb')
    model = cPickle.load(f)

elif args.cg:

    # Create the model
    model = ComputationalGraph(schema = yaml.load(open(args.cg,'r')),
                               log   = log,
                               learnRate = args.learnRate,
                               momentum  = args.momentum,
                               L1Reg = args.L1Reg,
                               L2Reg = args.L2Reg,
                               supCostWeight = args.supCostWeight,
                               unsupCostWeight = args.unsupCostWeight,
                               seed = args.seed)

if model.type in ['classifier','supervised-autoencoder']:
    targetType = np.int32
else:
    targetType = theano.config.floatX

# Check if GPU is being used or not
if np.any([isinstance(x.op, T.Elemwise) for x in model.predict.maker.fgraph.toposort()]):
    print 'No GPU found -- using CPU instead'
else:
    print 'Found GPU -- using that whenever possible'


# Write description of the model to infStream
infStream.write('\n' + str(model) + '\n')

if args.validData:

    infStream.write("Caching validation data for monitoring\n")

    x_valid,y_valid = DataReader(args.validData,
                                 targetType = targetType).cache()

infStream.write('\n')

if args.trainData:

    infStream.write("Starting to read input data for training\n")

    # Data reader for training
    drTrain = DataReader(args.trainData,
                         batchSize = args.batchSize,
                         targetType = targetType)
    
    nBatches = 0

    nTh = 100
    
    # Start training. Loops through the training data nPasses times
    for passIdx in xrange(args.nPasses):
        
        currMeanCost = 0.0
        
        n = 0
        
        for x_train,y_train in drTrain:
            
            nBatches += 1
            n += 1 

            if model.type == 'supervised-autoencoder':
                currMeanCost += model.hybrid_update(x_train,y_train) / n
            
            elif model.type == 'classifier':
                currMeanCost += model.supervised_update(x_train,y_train) / n
            elif model.type == 'autoencoder':
                currMeanCost += model.unsupervised_update(x_train) / n

            if n % nTh == 0:
                infStream.write('Pass ' + str(passIdx) + ', batch ' + 
                                str(nBatches) + ', avg. train cost ' + str(currMeanCost))

                if args.validData:
                    if model.type == 'classifier':
                        validCost = model.supervised_cost(x_valid,y_valid)
                        yhat = model.predict(x_valid)
                        pMisClass = np.mean(yhat != y_valid)
                        infStream.write(', validation cost ' + str(validCost) + 
                                        ', classification error ' + str(100*pMisClass) + "%")
                    elif model.type == 'autoencoder':
                        validCost = model.unsupervised_cost(x_valid)
                        infStream.write(', validation cost ' + str(validCost))
                    elif model.type == 'supervised-autoencoder':
                        validSupCost = model.supervised_cost(x_valid,y_valid)
                        validUnsupCost = model.unsupervised_cost(x_valid)
                        validHybCost = model.hybrid_cost(x_valid,y_valid)
                        yhat = model.predict(x_valid)
                        pMisClass = np.mean(yhat != y_valid)
                        infStream.write(', valid.sup.cost ' + str(validSupCost) +
                                        ', valid.unsup.cost ' + str(validUnsupCost) + 
                                        ', valid.hyb.cost ' + str(validHybCost) + 
                                        ', classification error ' + str(100*pMisClass) + "%")
                    

                infStream.write('\n')

                n = 0

                currMeanCost = 0.0

                if args.verbose:
                    model.summarizeParams()


        # After each successful pass, rewind the data reader for training
        drTrain.rewind()

infStream.write('\n')

if args.save:
    
    infStream.write('Saving model to file: ' + args.save + '\n')

    f = open(args.save,'wb')
    
    cPickle.dump(model,f,protocol=cPickle.HIGHEST_PROTOCOL)


def strVec(vec):
    if type(vec) in [np.int64,int,np.float64,float]:
        return str(vec)
    return ' '.join(map(str,vec))

def strMat(mat):
    return '\n'.join(strVec(map(strVec,row)) for row in mat)
    
if args.testData:

    infStream.write("Starting to read data for prediction\n")
    
    # Data reader for prediction
    drTest  = DataReader(args.testData,
                         batchSize = 1,
                         targetType = targetType)
    
    # Start prediction
    for x_test,y_test in drTest:

        if model.type in ['classifier','regressor']:
            
            outStream.write( strMat(zip(y_test,model.predict(x_test))) + '\n' )
            
        elif model.type == 'autoencoder':
            
            outStream.write( strMat(zip(y_test,model.encode(x_test))) + '\n' )

        elif model.type == 'supervised-autoencoder':

            outStream.write( strMat(zip(y_test,
                                        model.predict(x_test),
                                        model.encode(x_test),
                                        model.decode(x_test))) + '\n' )









#!/usr/bin/python

import sys
import argparse
import theano.tensor as T
import numpy as np

from cgml.io import DataReader
from cgml.data import makeRandomClassificationData, makeRandomRegressionData
from cgml.optimizers import MSGD
from cgml.classifiers import LogRegClassifier,MultiLayerPerceptronClassifier
#from cgml.costs import negativeLogLikelihood,squaredLoss
#from cgml.bench import trainTestBench
from cgml.trainers import OnlineTrainer
from cgml.argparse_actions import giveArgs

outStream = sys.stdout

args = giveArgs(log = outStream)

drTrain = DataReader(args.trainData)
drTest  = DataReader(args.testData)

n_in = drTrain.nInputs
n_out = args.nClasses

x = T.dmatrix('x')
y = T.lvector('y')

model = args.Model(
    x     = x,
    n_in  = n_in,
    n_out = n_out)

cost = args.Cost(model.output,y)

# Use mini-batch stochastic gradient descent to optimize parameters 
msgd_optimizer = MSGD(
    cost      = cost,
    params    = model.params,
    learnRate = args.learnRate)

oTrainer = OnlineTrainer(
    x = x,
    y = y,
    model = model,
    cost = cost,
    optimizer = msgd_optimizer)

for passIdx in xrange(args.nPasses):

    for x_train,y_train in drTrain:
        oTrainer.update(x_train,y_train)

    drTrain.rewind()














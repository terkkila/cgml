#!/usr/bin/python

import sys
import argparse
import theano
import theano.tensor as T
import numpy as np
import yaml
import json

from cgml.io import ppf
from cgml.io import DataReader
from cgml.argparse_actions import giveArgs
from cgml.computational_graph import ComputationalGraph

# Print info here
infStream = sys.stderr

# Parsing the arguments
args = giveArgs(log = infStream)

# Print outputs here
if args.predictions:
    outStream = open(args.predictions,'w')
else:
    outStream = None

# Open a log if needed
#log = ( open(args.log,'w') if args.log else None )

if args.load:

    infStream.write('\nLoading model from file: ' + args.load + '\n')

    model = ComputationalGraph.loadFromFile(args.load)

elif args.cg:

    # Create the model
    model = ComputationalGraph(schema = yaml.load(open(args.cg,'r')),
                               log   = infStream,
                               supCostWeight = args.supCostWeight,
                               unsupCostWeight = args.unsupCostWeight,
                               seed = args.seed)

if args.recompileOnLoad:
    model.compile(log = infStream)

#if model.type not in ['autoencoder']:
infStream.write(str(model.predict.maker.fgraph.toposort())+'\n')

# Check if GPU is being used or not
if np.any([isinstance(x.op, T.Elemwise) for x in model.predict.maker.fgraph.toposort()]):
    infStream.write('No GPU found -- using CPU instead\n')
else:
    infStream.write('Found GPU -- using that whenever possible\n')


# Write description of the model to infStream
infStream.write('\n' + str(model) + '\n')

if args.validData:

    infStream.write("Caching validation data for monitoring\n")

    sampleIDs,xValid,yValid = DataReader(args.validData,
                                         targetType = model.targetType).cache()

else:

    xValid,yValid = None,None


infStream.write('\n')

if args.trainData or args.trainDataStream:

    infStream.write("Starting to read input data for training\n")

    if args.trainData:
        
        # Data reader from file
        drTrain = DataReader(args.trainData,
                             batchSize = args.deviceBatchSize,
                             targetType = model.targetType)
     
    else:

        # Data reader from stream
        drTrain = DataReader(sys.stdin,
                             batchSize = args.deviceBatchSize,
                             targetType = model.targetType)
        

    model.train(drTrain = drTrain,
                x_valid = xValid,
                y_valid = yValid,
                nPasses = args.nPasses,
                deviceBatchSize = args.deviceBatchSize,
                miniBatchSize = args.miniBatchSize,
                verbose = args.verbose,
                infStream = infStream)

infStream.write('\n')

if args.save:
    
    infStream.write('Saving model to file: ' + args.save + '\n')

    model.saveToFile(args.save)

def strVec(vec):
    if type(vec) in [np.int64,int,np.float64,float]:
        return str(vec)
    return ' '.join(map(str,vec))

def strMat(mat):
    return '\n'.join(strVec(map(strVec,row)) for row in mat)
    
if args.testData:

    infStream.write("Starting to read data for prediction\n")
    
    if not args.predictions:
        infStream.write("WARNING: no predictions file provided! Predictions will not be saved\n")

    # Data reader for prediction
    drTest  = DataReader(args.testData,
                         batchSize = 1,
                         targetType = model.targetType)
    
    # Start prediction
    for sampleIDs,x_test,y_test in drTest:

        if model.type in ['classification','regression']:
            
            for sampleID,xi_test,yi_test,yhati_test,impi_test in zip(sampleIDs,
                                                                     x_test,
                                                                     y_test,
                                                                     model.predict(x_test),
                                                                     model.importance(x_test)):
                
                predObj = {"sampleID":sampleID,
                           "y":yi_test.tolist(),
                           "yhat":yhati_test.tolist()}

                if args.getImportance:
                    predObj["importance"] = impi_test
                
                if outStream:
                    outStream.write(json.dumps(predObj) + "\n")
                            
        elif model.type == 'autoencoder':
            
            if outStream:
                outStream.write( strMat(zip([y_test],model.encode(x_test))) + '\n' )
            
        elif model.type == 'supervised-autoencoder':
            
            if outStream:
                outStream.write( strMat(zip([y_test],
                                            model.predict(x_test),
                                            model.encode(x_test),
                                            model.decode(x_test))) + '\n' )
            
            






